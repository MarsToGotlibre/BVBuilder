{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c1879b",
   "metadata": {},
   "source": [
    "# CSV to PDF pipeline\n",
    "This Notebook aims to help you modify the json output to your liking if none of the already available outputs suits you.  \n",
    "This notebook suppose that you have the folowing dependencies installed :\n",
    "- Pyhton 3  \n",
    "\n",
    "And the following library : \n",
    "- pandas  \n",
    "\n",
    "If you haven't installed it  you can uncomment the following code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30a9f5",
   "metadata": {},
   "source": [
    "The original pipeline depend on a config element configurated by the user options. \n",
    "This options are :\n",
    "- large json\n",
    "- inline downgades\n",
    "- reduction category\n",
    "- goe\n",
    "\n",
    "In order to see what are the default outputs of the json and what each option does, you can read the Json Outpout section of the Readme.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2120d",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "- [Initial setup](#initial-setup)\n",
    "- [Options](#options)\n",
    "    - [Reduction category](#reduction-category)\n",
    "    - [Downgrades value](#downgrades-value)\n",
    "    - [Large output](#large-output)\n",
    "- [Creation of elements entry](#creation-of-elements-entries)\n",
    "- [Pipeline](#pipeline)\n",
    "- [Write the json file](#write-the-json-file)\n",
    "\n",
    "- [Playground](#playground) : enter the path of your csv file, choose your config and experiment with the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aead400",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12504188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159a6fe",
   "metadata": {},
   "source": [
    "And a variable `GOE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOE= ['-5', '-4', '-3', '-2', '-1', 'BASE', '1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf736375",
   "metadata": {},
   "source": [
    "The config class that will be used by the pipeline. Most of the functions takes a config class as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, largeOutput=False, inline_downgrades=False, reductionCategory=False, goe=False):\n",
    "        self.largeOutput = largeOutput\n",
    "        self.inline_downgrades = inline_downgrades\n",
    "        self.reductionCategory = reductionCategory\n",
    "        self.goe = goe\n",
    "    \n",
    "    @classmethod\n",
    "    def synchro_skate_calc(cls):\n",
    "        return cls(False,False,True,False)\n",
    "    \n",
    "    def inline_dg(self,value:bool):\n",
    "        self.inline_downgrades=value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bf832",
   "metadata": {},
   "source": [
    "# Options\n",
    "## Reduction Category\n",
    "This sections is devided in two parts :\n",
    "- Verifying this can actually be made (are the category actually equal)\n",
    "- If this can be made, create a entry in the json for this category.\n",
    "\n",
    "### Are the category equal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86006384",
   "metadata": {},
   "source": [
    "The first functions searches for category which have different elements under the same category name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3958ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindCategoryofElements(df,categorylist): #=df[\"Category\"].unique()\n",
    "    List=[]\n",
    "    for category in categorylist:\n",
    "        Cat=df.query(f\"Category == '{category}'\")[\"Element\"].unique()\n",
    "        if len(Cat)>1:\n",
    "            List.append({\"Category\":category,\"Elements\":Cat})\n",
    "    return List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d712cd9",
   "metadata": {},
   "source": [
    "The goal here is to determine whether all elements under a category behave the same.\n",
    "For example, if all Artistic Elements have identical GOE and base-value rows, then they can be merged into a single JSON section.\n",
    "\n",
    "- `FindCategoryofElements()` builds a list of :\n",
    "`{\"Category\": \"ARTISTIC ELEMENTS\", \"Elements\": [\"AC\", \"AB\", \"AW\", \"AL\"]}`\n",
    "\n",
    "- `CategoryEqual()` checks whether these elements all share the same GOE table. `ListElem` is assumed to be the `\"Elements\"` list of a dictionnary in the list returned by `FindCategoryofElements()`\n",
    "\n",
    "If they do, the category can be reduced into a single JSON entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522df6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoryEqual(df,ListElem):\n",
    "    temp=df.query(f\"ElmtName == '{ListElem[0]}'\")[GOE]\n",
    "    for i in range(1,len(ListElem)):\n",
    "        elem=df.query(f\"ElmtName == '{ListElem[i]}'\")[GOE]\n",
    "        if not elem.reset_index(drop=True).equals(temp.reset_index(drop=True)): # if the Two dataframes are different\n",
    "            return False\n",
    "        else:\n",
    "            temp=elem\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df787bf6",
   "metadata": {},
   "source": [
    "### Creating category entries\n",
    "The following function takes a dictElement which is the dictionnairy that will turn into a json in the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61b180",
   "metadata": {},
   "source": [
    "The implementation of category names is build on the element name (`Element` column of the CSV), which is assumed to have the following pattern :  \n",
    "**[category Symbol] + [Element Symbol]**  \n",
    "\n",
    "Here the element symbol is assumed to be a single letter such as :\n",
    "- `AB` is a variation of `B`, assumed category symbol : `A`\n",
    "- `CrI` is a variation of `I`, assumed category symbol : `Cr`\n",
    "\n",
    "But for some categories, such as *LINEAR AND ROTATING ELEMENTS*, the  are only composed of one Letter. So instead the category name will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reductionCategory(df,dictElement,config:Config):\n",
    "    cat=FindCategoryofElements(df,df[\"Category\"].unique())\n",
    "   \n",
    "    if  not config.inline_downgrades:\n",
    "        query=\"DGrade == 0\"\n",
    "        tempdf = df.query(query)\n",
    "    else:\n",
    "        query=\"\"\n",
    "        tempdf=df\n",
    "    for i in range(len(cat)):\n",
    "        equal=CategoryEqual(tempdf,cat[i][\"Elements\"])\n",
    "        if equal:\n",
    "            \n",
    "            # Define Element name in the json\n",
    "            name=cat[i][\"Elements\"][0][:-1] if len(cat[i][\"Elements\"][0])>1 else cat[i][\"Category\"]\n",
    "\n",
    "            #Create name in the dictionnary\n",
    "            dictElement[name]={}\n",
    "            fillElement(tempdf.query(f\"Element == '{cat[i][\"Elements\"][0]}'\"),config,dictElement[name])\n",
    "            \n",
    "            if len(query)>0:\n",
    "                query+= f\" and Category != '{cat[i]['Category']}'\"\n",
    "            else :\n",
    "                query+= f\"Category != '{cat[i]['Category']}'\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe42f4",
   "metadata": {},
   "source": [
    "## Downgrades value\n",
    "This is one of the the default features. This option adds the Donwgrades as an element element.  \n",
    "\n",
    "- This part assumes that only two donwgrades exists : `<` and `<<`\n",
    "- The downgrades also assumed to be a fixed value and independent of the element and level of the element\n",
    "- Since the presence of downgrades is recent, no downgrades will be added to the json if none are found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69373cdf",
   "metadata": {},
   "source": [
    "The first function is to found downgrades values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDGval(df):\n",
    "    try :\n",
    "        rowdg1=df.query(\"DGrade == 1\").iloc[0]\n",
    "        rowdg2=df.query(\"DGrade == 2\").iloc[0]\n",
    "        row1=df.query(f\"Element == '{rowdg1[\"Element\"]}' and ElmntLvl == '{rowdg1[\"ElmntLvl\"]}' and DGrade == 0\")\n",
    "        row2=df.query(f\"Element == '{rowdg2[\"Element\"]}' and ElmntLvl == '{rowdg2[\"ElmntLvl\"]}' and DGrade == 0\")\n",
    "        return ((row1[\"BASE\"]-rowdg1[\"BASE\"]).iloc[0],(row2[\"BASE\"]-rowdg2[\"BASE\"]).iloc[0])\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"find Downgrade Value Failed : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13861110",
   "metadata": {},
   "source": [
    "The second is to verify, all downgrades values applied are equal. Which means if we put  a downgrade on a Level 4 element the value of the downgrade applied will be the same as if it was Level 1. (Independence assumtumption)  \n",
    "\n",
    "You may not use this function in your pipeline if you are sure all downgrades are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DowngradesValueEqual(df,dg): #=findDGval(df)\n",
    "    dgdf=df.query(\"DGrade != 0\")\n",
    "    for tup in dgdf.itertuples():\n",
    "        temp=(df.query(f\"Element == '{tup.Element}' and ElmntLvl == '{tup.ElmntLvl}' and DGrade == 0\")[\"BASE\"]-tup.BASE).iloc[0]\n",
    "        if not dg[tup.DGrade-1]==temp:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6ae0a",
   "metadata": {},
   "source": [
    "## Large output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LargeJson(df):\n",
    "    element={}\n",
    "    for row in df.itertuples():\n",
    "        if pd.isna(row.AFNot) or row.AFNot ==\"-\":\n",
    "            element[row.ElmtNot]={\"base\":row.BASE,\"goe\":dict(zip(GOE,row[7:18]))}\n",
    "        else :\n",
    "            element[row.ElmtNot+\"+\"+row.AFNot]={\"base\":row.BASE,\"goe\":dict(zip(GOE,row[7:18]))}\n",
    "    return element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868162e",
   "metadata": {},
   "source": [
    "The output of this function can then directly be converted into a json."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e777f",
   "metadata": {},
   "source": [
    "# Creation of Elements entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a63ca2",
   "metadata": {},
   "source": [
    "This part handle the ouput of each element in the json, for each level. The default value attrubuterd is the base value, this can be changed thought the goe option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125421f7",
   "metadata": {},
   "source": [
    "The role  of the first function si to determin what will be at the end of the json : \n",
    "```json\n",
    "{\"element\" : \n",
    "    {\"level\": /* <BASE Value> or this dictionnary : {\"base\": <BASE> , \"goe\":{ <goe columns> }}*/\n",
    "    }\n",
    "}\n",
    "```\n",
    "You can modify it by making it return anything. The tupple attributes are the same as the csv columns exept for the goe that have columns name as number so they have to be called with `[]`.   \n",
    "\n",
    "The Goe correspond to the following indexes :\n",
    "-  `'-5'`, `'-4'`, `'-3'`, `'-2'`, `'-1'` correspond to the index 7 to 11\n",
    "- `'1'`, `'2'`, `'3'`, `'4'`, `'5'` to the indexes from 13 to 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputValue(tup,config:Config):\n",
    "    if config.goe:\n",
    "        return {\"base\":tup.BASE,\"goe\":dict(zip(GOE,tup[7:18]))}\n",
    "    else :\n",
    "        return tup.BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7344dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DowngradeKey(DowngradeValue):\n",
    "    return \"NoDg\" if DowngradeValue==0 else DowngradeValue*\"<\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce095ae",
   "metadata": {},
   "source": [
    "The element is the dictionary of the dictionnary associated to the element. More informations may be added in the [pipeline](#pipeline) or directly next to the levels though `outputValue()` or any other manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffebdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillElement(elementGroup,config:Config,element):\n",
    "    \n",
    "    #Without Additional Feature\n",
    "    if elementGroup[\"AFNot\"].isna().all():\n",
    "        if not config.inline_downgrades:\n",
    "            for Lvl in elementGroup.itertuples():\n",
    "                element[Lvl.ElmntLvl]=outputValue(Lvl,config)\n",
    "        else:\n",
    "            for LvlElem,GroupLvl in elementGroup.groupby(\"ElmntLvl\"):\n",
    "                element[LvlElem]={}\n",
    "                for Dg in GroupLvl.itertuples():\n",
    "                    key=DowngradeKey(Dg.DGrade)\n",
    "                    element[LvlElem][key]=outputValue(Dg,config)\n",
    "   #with additional Feature                 \n",
    "    else:\n",
    "        if not config.inline_downgrades:\n",
    "            for LvlElem,GroupLvl in elementGroup.groupby('ElmntLvl'):\n",
    "                element[LvlElem]={}\n",
    "                for AddF in GroupLvl.itertuples():\n",
    "                    element[LvlElem][AddF.AFNot]=outputValue(AddF,config)\n",
    "        else:\n",
    "            for LvlElem,GroupLvl in elementGroup.groupby(\"ElmntLvl\"):\n",
    "                element[LvlElem]={}\n",
    "                for AddF,GroupAF in GroupLvl.groupby(\"AFNot\"):\n",
    "                    element[LvlElem][AddF]={}\n",
    "                    for Dg in GroupAF.itertuples():\n",
    "                        key=DowngradeKey(Dg.DGrade)\n",
    "                        element[LvlElem][AddF][key]=outputValue(Dg,config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194bca8",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "- The following function creates the dictionary that will then be transformed into a json file.\n",
    "\n",
    "- When searching for downgrades, if downgrades aren't equals with in each others, inline downgrade option will be applied even if it wasn't selected\n",
    "\n",
    "- You can change the keys of the elements, add information for each elements..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnDict(df,config:Config):\n",
    "    if config.largeOutput:\n",
    "        \n",
    "        return LargeJson(df)\n",
    "    \n",
    "    dictElement={}\n",
    "    dg=findDGval(df)\n",
    "    query=\"\"\n",
    "    if dg!=None :\n",
    "        if not DowngradesValueEqual(df,dg) :\n",
    "            logging.info(\"Downgrades values aren't equal\")\n",
    "            if config.inline_dg == False :\n",
    "                config.inline_dg(True)\n",
    "                logging.warning(\"Inline downgrade option will be applied\")\n",
    "\n",
    "        \n",
    "        if not config.inline_downgrades:\n",
    "            dictElement[\"Downgrades\"]=dict(zip([\"<\",\"<<\"],dg))\n",
    "            query=\"DGrade == 0\"\n",
    "            logging.info(\"Downgrades Separated\")\n",
    "\n",
    "    if config.reductionCategory:\n",
    "        query=reductionCategory(df,dictElement,config)\n",
    "        logging.info(\"Category reducted\")\n",
    "    \n",
    "    iterDf= df.query(query) if query else df\n",
    "    \n",
    "    for elem,group in iterDf.groupby('Element'):\n",
    "        dictElement[elem]={}\n",
    "        fillElement(group,config,dictElement[elem])\n",
    "    logging.info(\"Json structure finished\")\n",
    "    return dictElement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b2b27",
   "metadata": {},
   "source": [
    "# Write the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9887a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnJsonFile(input,config:Config,output):\n",
    "    df=pd.read_csv(input)\n",
    "    JsonDict=returnDict(df,config)\n",
    "    with open(output,\"w\") as f :\n",
    "        json.dump(JsonDict,f,indent=4)\n",
    "    logging.info(f\"Json genrerated in : {output}\")\n",
    "\n",
    "#returnJsonFile(filename.csv,config,output.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce8c3b",
   "metadata": {},
   "source": [
    "# Playground\n",
    "Here you can experiment. You just have to fill the following fields to then be able to use the functions  more conviniently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ee41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=#\"you_csv_file.csv\"\n",
    "outptput_file#\"your_output_json.json\"\n",
    "df=pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009845b",
   "metadata": {},
   "source": [
    "Your `Config` object :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcec968",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config(largeOutput=False, inline_downgrades=False, reductionCategory=False, goe=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
